{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### First get the candidate model parts (Head and Feature Extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T14:04:27.798677Z",
     "end_time": "2023-04-20T14:04:33.757553Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/20 14:04:29 WARNING mlflow.pytorch: Stored model version '1.13.1' does not match installed PyTorch version '2.0.0'\n"
     ]
    },
    {
     "data": {
      "text/plain": "DiffFeatureDetectorParamBiDirectional(\n  (cls_layer): Sequential(\n    (features_dropout): Dropout(p=0.31296189949335906, inplace=False)\n    (linear_0): Linear(in_features=1280, out_features=184, bias=True)\n    (relu_0): ReLU()\n    (hidden_dropout_0): Dropout(p=0.5838650129135917, inplace=False)\n    (linear_1): Linear(in_features=184, out_features=184, bias=True)\n    (relu_1): ReLU()\n    (hidden_dropout_1): Dropout(p=0.5838650129135917, inplace=False)\n    (linear_2): Linear(in_features=184, out_features=184, bias=True)\n    (relu_2): ReLU()\n    (hidden_dropout_2): Dropout(p=0.5838650129135917, inplace=False)\n    (linear_out): Linear(in_features=184, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "model_uri = \"models:/{}/{}\".format('Laion Balanced', '1')\n",
    "head_model = mlflow.pytorch.load_model(model_uri)\n",
    "head_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T22:29:33.174347Z",
     "end_time": "2023-04-16T22:30:03.030501Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/20 14:03:54 WARNING mlflow.pytorch: Stored model version '1.13.1' does not match installed PyTorch version '2.0.0'\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47f942be19254ea29f44a0d68b1f4df6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b514010f5d134ef4ae7d109bd85a2b51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from drecg.training.ignite_finetune import define_model_for_tune\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "model_1 = define_model_for_tune('Laion Balanced', 'ViT_LAION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from drecg.feature_extraction.distributed import VitImageFeatureExtractor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T13:59:19.044719Z",
     "end_time": "2023-04-21T13:59:20.461303Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in HuggingFace Hub.\n"
     ]
    }
   ],
   "source": [
    "model = VitImageFeatureExtractor.load_pretrained()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T13:59:20.462480Z",
     "end_time": "2023-04-21T13:59:30.984810Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "seq_model = model.to_sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T13:59:30.986190Z",
     "end_time": "2023-04-21T13:59:30.987929Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Sequential(\n    (0): CLIPVisionEmbeddings(\n      (patch_embedding): Conv2d(3, 1664, kernel_size=(14, 14), stride=(14, 14), bias=False)\n      (position_embedding): Embedding(257, 1664)\n    )\n    (1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n  )\n  (1): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (2): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (3): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (4): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (5): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (6): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (7): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (8): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (9): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (10): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (11): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (12): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (13): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (14): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (15): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (16): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (17): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (18): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (19): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (20): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (21): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (22): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (23): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (24): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (25): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (26): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (27): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (28): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (29): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (30): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (31): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (32): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (33): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (34): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (35): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (36): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (37): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (38): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (39): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (40): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (41): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (42): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (43): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (44): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (45): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (46): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (47): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (48): EncoderLayerSimple(\n    (enc_layer): CLIPEncoderLayer(\n      (self_attn): CLIPAttention(\n        (k_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (v_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (q_proj): Linear(in_features=1664, out_features=1664, bias=True)\n        (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n      )\n      (layer_norm1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n      (mlp): CLIPMLP(\n        (activation_fn): GELUActivation()\n        (fc1): Linear(in_features=1664, out_features=8192, bias=True)\n        (fc2): Linear(in_features=8192, out_features=1664, bias=True)\n      )\n      (layer_norm2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (49): EncoderPostLayer(\n    (post_layernorm): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n  )\n  (50): Linear(in_features=1664, out_features=1280, bias=False)\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T13:59:41.035282Z",
     "end_time": "2023-04-21T13:59:41.056316Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch\n",
    "dummy_tensor_input = torch.rand(3, 3, 224, 224)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T13:59:47.403446Z",
     "end_time": "2023-04-21T13:59:47.420520Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "out_0 = model(dummy_tensor_input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T13:51:53.590372Z",
     "end_time": "2023-04-21T13:51:59.130526Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "out_1 = seq_model(dummy_tensor_input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T14:00:32.710738Z",
     "end_time": "2023-04-21T14:00:38.311856Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(out_0, out_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T13:52:30.925626Z",
     "end_time": "2023-04-21T13:52:30.931943Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b914bfb3d79f40ef9221c3b68d54ade2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "original_laion_model = AutoModel.from_pretrained(\"laion/CLIP-ViT-bigG-14-laion2B-39B-b160k\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T13:59:50.892850Z",
     "end_time": "2023-04-21T14:00:09.681248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "original_laion_model.eval();"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T14:00:17.829112Z",
     "end_time": "2023-04-21T14:00:17.847491Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "out_2 = original_laion_model.get_image_features(pixel_values=dummy_tensor_input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T14:00:21.508598Z",
     "end_time": "2023-04-21T14:00:27.094915Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(out_1, out_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T14:00:53.270878Z",
     "end_time": "2023-04-21T14:00:53.313089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers.models.clip.modeling_clip import CLIPModel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_laion_model.get_image_features(torch.rand(3, 3, 224, 224))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "class Extractor(torch.nn.Module):\n",
    "    def __init__(self, vision_model):\n",
    "        super().__init__()\n",
    "        self.vision_model = vision_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        img_a, img_b = x\n",
    "        return self.vision_model(img_a), self.vision_model(img_b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T22:54:17.244380Z",
     "end_time": "2023-04-16T22:54:17.246192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Only model weights in GPU: 7.9 GB\n",
    "#Batch of 4 images pairs forward pass: +13.5GB\n",
    "#Batch of 4 images pairs backward pass: +5GB\n",
    "#Fordward pass time GPU batch 4 pairs: 300 ms\n",
    "#forward + Backward  pass time CPU batch 4 pairs: 13 segs + 40 segs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T22:54:41.951562Z",
     "end_time": "2023-04-16T22:54:41.997410Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in HuggingFace Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, loss: 1.5391587018966675, time: 32.90772318840027 segs\n",
      "iter: 1, loss: 3.576278118089249e-07, time: 32.02351236343384 segs\n",
      "iter: 2, loss: 1.0216133887297474e-05, time: 31.575616121292114 segs\n",
      "iter: 3, loss: 9.691621016827412e-06, time: 31.562179565429688 segs\n",
      "iter: 4, loss: 5.960463766996327e-08, time: 31.31337833404541 segs\n",
      "iter: 5, loss: 0.002470702398568392, time: 31.104001760482788 segs\n",
      "iter: 6, loss: 0.0, time: 31.410987615585327 segs\n",
      "iter: 7, loss: 0.0, time: 31.036481857299805 segs\n",
      "iter: 8, loss: 0.0, time: 31.05917716026306 segs\n",
      "iter: 9, loss: 0.0, time: 31.293527126312256 segs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '29500'\n",
    "torch.distributed.rpc.init_rpc('worker', rank=0, world_size=1)\n",
    "from drecg.feature_extraction.distributed import sequential_model_to_devices\n",
    "\n",
    "from torch.distributed.pipeline.sync import Pipe\n",
    "from drecg.feature_extraction.distributed import VitImageFeatureExtractor\n",
    "model = VitImageFeatureExtractor.load_pretrained()\n",
    "\n",
    "model_seq = model.to_sequential()\n",
    "model_seq.add_module('head', nn.Linear(1280, 1))\n",
    "\n",
    "device0 = torch.device(\"cuda:0\")\n",
    "device1 = torch.device(\"cpu\")\n",
    "sequential_model_to_devices(model_seq, device0, device1)\n",
    "model_pipe = Pipe(model_seq, chunks=2)\n",
    "\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "y_true = torch.ones(10, 1, dtype=torch.float32)\n",
    "\n",
    "model_pipe.train()\n",
    "adam_w = torch.optim.AdamW(model_pipe.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(10):\n",
    "    init_time = time.time()\n",
    "    dummy_tensor_input = torch.rand(10, 3, 224, 224)\n",
    "    dummy_tensor_input = dummy_tensor_input.to(device0)\n",
    "    adam_w.zero_grad()\n",
    "    out = model_pipe(dummy_tensor_input)\n",
    "    out = out.local_value()\n",
    "    loss = loss_fn(out, y_true)\n",
    "    loss.backward()\n",
    "    adam_w.step()\n",
    "    total_time_segs = time.time() - init_time\n",
    "    print(\"iter: {}, loss: {}, time: {} segs\".format(i, loss.item(), total_time_segs))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T19:40:18.288933Z",
     "end_time": "2023-04-23T19:45:46.413102Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dogrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd0d7e94ccb776d367f1b5708497d31240ae7624b420edef6e7d497eefa657d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
